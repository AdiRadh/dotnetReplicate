using System;
using System.Collections;
using System.Collections.Generic;
using System.Collections.ObjectModel;
using System.Linq;
using System.IO;
using System.Runtime.Serialization;
using System.Text;
using System.Text.RegularExpressions;
using Newtonsoft.Json;
using Newtonsoft.Json.Converters;
using Newtonsoft.Json.Linq;
using System.ComponentModel.DataAnnotations;
using OpenAPIDateConverter = dotnetReplicate.Client.OpenAPIDateConverter;

namespace dotnetReplicate.Model
{
    /// <summary>
    /// PredictionsCreateRequest
    /// </summary>
    [DataContract(Name = "predictions_create_request")]
    public partial class PredictionsCreateRequest : IValidatableObject
    {
        /// <summary>
        /// Defines WebhookEventsFilter
        /// </summary>
        [JsonConverter(typeof(StringEnumConverter))]
        public enum WebhookEventsFilterEnum
        {
            /// <summary>
            /// Enum Start for value: start
            /// </summary>
            [EnumMember(Value = "start")]
            Start = 1,

            /// <summary>
            /// Enum Output for value: output
            /// </summary>
            [EnumMember(Value = "output")]
            Output = 2,

            /// <summary>
            /// Enum Logs for value: logs
            /// </summary>
            [EnumMember(Value = "logs")]
            Logs = 3,

            /// <summary>
            /// Enum Completed for value: completed
            /// </summary>
            [EnumMember(Value = "completed")]
            Completed = 4
        }

        /// <summary>
        /// Initializes a new instance of the <see cref="PredictionsCreateRequest" /> class.
        /// </summary>
        [JsonConstructorAttribute]
        protected PredictionsCreateRequest() { }
        /// <summary>
        /// Initializes a new instance of the <see cref="PredictionsCreateRequest" /> class.
        /// </summary>
        /// <param name="input">The model&#39;s input as a JSON object. The input schema depends on what model you are running. To see the available inputs, click the \&quot;API\&quot; tab on the model you are running or [get the model version](#models.versions.get) and look at its &#x60;openapi_schema&#x60; property. For example, [stability-ai/sdxl](https://replicate.com/stability-ai/sdxl) takes &#x60;prompt&#x60; as an input.  Files should be passed as HTTP URLs or data URLs.  Use an HTTP URL when:  - you have a large file &gt; 256kb - you want to be able to use the file multiple times - you want your prediction metadata to be associable with your input files  Use a data URL when:  - you have a small file &lt;&#x3D; 256kb - you don&#39;t want to upload and host the file somewhere - you don&#39;t need to use the file again (Replicate will not store it)  (required).</param>
        /// <param name="stream">Request a URL to receive streaming output using [server-sent events (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events).  If the requested model version supports streaming, the returned prediction will have a &#x60;stream&#x60; entry in its &#x60;urls&#x60; property with an HTTPS URL that you can use to construct an [&#x60;EventSource&#x60;](https://developer.mozilla.org/en-US/docs/Web/API/EventSource). .</param>
        /// <param name="varVersion">The ID of the model version that you want to run. (required).</param>
        /// <param name="webhook">An HTTPS URL for receiving a webhook when the prediction has new output. The webhook will be a POST request where the request body is the same as the response body of the [get prediction](#predictions.get) operation. If there are network problems, we will retry the webhook a few times, so make sure it can be safely called more than once. .</param>
        /// <param name="webhookEventsFilter">By default, we will send requests to your webhook URL whenever there are new outputs or the prediction has finished. You can change which events trigger webhook requests by specifying &#x60;webhook_events_filter&#x60; in the prediction request:  - &#x60;start&#x60;: immediately on prediction start - &#x60;output&#x60;: each time a prediction generates an output (note that predictions can generate multiple outputs) - &#x60;logs&#x60;: each time log output is generated by a prediction - &#x60;completed&#x60;: when the prediction reaches a terminal state (succeeded/canceled/failed)  For example, if you only wanted requests to be sent at the start and end of the prediction, you would provide:  &#x60;&#x60;&#x60;json {   \&quot;version\&quot;: \&quot;5c7d5dc6dd8bf75c1acaa8565735e7986bc5b66206b55cca93cb72c9bf15ccaa\&quot;,   \&quot;input\&quot;: {     \&quot;text\&quot;: \&quot;Alice\&quot;   },   \&quot;webhook\&quot;: \&quot;https://example.com/my-webhook\&quot;,   \&quot;webhook_events_filter\&quot;: [\&quot;start\&quot;, \&quot;completed\&quot;] } &#x60;&#x60;&#x60;  Requests for event types &#x60;output&#x60; and &#x60;logs&#x60; will be sent at most once every 500ms. If you request &#x60;start&#x60; and &#x60;completed&#x60; webhooks, then they&#39;ll always be sent regardless of throttling. .</param>
        public PredictionsCreateRequest(Object input = default(Object), bool stream = default(bool), string varVersion = default(string), string webhook = default(string), List<WebhookEventsFilterEnum> webhookEventsFilter = default(List<WebhookEventsFilterEnum>))
        {
            // to ensure "input" is required (not null)
            if (input == null)
            {
                throw new ArgumentNullException("input is a required property for PredictionsCreateRequest and cannot be null");
            }
            this.Input = input;
            // to ensure "varVersion" is required (not null)
            if (varVersion == null)
            {
                throw new ArgumentNullException("varVersion is a required property for PredictionsCreateRequest and cannot be null");
            }
            this.VarVersion = varVersion;
            this.Stream = stream;
            this.Webhook = webhook;
            this.WebhookEventsFilter = webhookEventsFilter;
        }

        /// <summary>
        /// The model&#39;s input as a JSON object. The input schema depends on what model you are running. To see the available inputs, click the \&quot;API\&quot; tab on the model you are running or [get the model version](#models.versions.get) and look at its &#x60;openapi_schema&#x60; property. For example, [stability-ai/sdxl](https://replicate.com/stability-ai/sdxl) takes &#x60;prompt&#x60; as an input.  Files should be passed as HTTP URLs or data URLs.  Use an HTTP URL when:  - you have a large file &gt; 256kb - you want to be able to use the file multiple times - you want your prediction metadata to be associable with your input files  Use a data URL when:  - you have a small file &lt;&#x3D; 256kb - you don&#39;t want to upload and host the file somewhere - you don&#39;t need to use the file again (Replicate will not store it) 
        /// </summary>
        /// <value>The model&#39;s input as a JSON object. The input schema depends on what model you are running. To see the available inputs, click the \&quot;API\&quot; tab on the model you are running or [get the model version](#models.versions.get) and look at its &#x60;openapi_schema&#x60; property. For example, [stability-ai/sdxl](https://replicate.com/stability-ai/sdxl) takes &#x60;prompt&#x60; as an input.  Files should be passed as HTTP URLs or data URLs.  Use an HTTP URL when:  - you have a large file &gt; 256kb - you want to be able to use the file multiple times - you want your prediction metadata to be associable with your input files  Use a data URL when:  - you have a small file &lt;&#x3D; 256kb - you don&#39;t want to upload and host the file somewhere - you don&#39;t need to use the file again (Replicate will not store it) </value>
        [DataMember(Name = "input", IsRequired = true, EmitDefaultValue = true)]
        public Object Input { get; set; }

        /// <summary>
        /// Request a URL to receive streaming output using [server-sent events (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events).  If the requested model version supports streaming, the returned prediction will have a &#x60;stream&#x60; entry in its &#x60;urls&#x60; property with an HTTPS URL that you can use to construct an [&#x60;EventSource&#x60;](https://developer.mozilla.org/en-US/docs/Web/API/EventSource). 
        /// </summary>
        /// <value>Request a URL to receive streaming output using [server-sent events (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events).  If the requested model version supports streaming, the returned prediction will have a &#x60;stream&#x60; entry in its &#x60;urls&#x60; property with an HTTPS URL that you can use to construct an [&#x60;EventSource&#x60;](https://developer.mozilla.org/en-US/docs/Web/API/EventSource). </value>
        [DataMember(Name = "stream", EmitDefaultValue = true)]
        public bool Stream { get; set; }

        /// <summary>
        /// The ID of the model version that you want to run.
        /// </summary>
        /// <value>The ID of the model version that you want to run.</value>
        [DataMember(Name = "version", IsRequired = true, EmitDefaultValue = true)]
        public string VarVersion { get; set; }

        /// <summary>
        /// An HTTPS URL for receiving a webhook when the prediction has new output. The webhook will be a POST request where the request body is the same as the response body of the [get prediction](#predictions.get) operation. If there are network problems, we will retry the webhook a few times, so make sure it can be safely called more than once. 
        /// </summary>
        /// <value>An HTTPS URL for receiving a webhook when the prediction has new output. The webhook will be a POST request where the request body is the same as the response body of the [get prediction](#predictions.get) operation. If there are network problems, we will retry the webhook a few times, so make sure it can be safely called more than once. </value>
        [DataMember(Name = "webhook", EmitDefaultValue = false)]
        public string Webhook { get; set; }

        /// <summary>
        /// By default, we will send requests to your webhook URL whenever there are new outputs or the prediction has finished. You can change which events trigger webhook requests by specifying &#x60;webhook_events_filter&#x60; in the prediction request:  - &#x60;start&#x60;: immediately on prediction start - &#x60;output&#x60;: each time a prediction generates an output (note that predictions can generate multiple outputs) - &#x60;logs&#x60;: each time log output is generated by a prediction - &#x60;completed&#x60;: when the prediction reaches a terminal state (succeeded/canceled/failed)  For example, if you only wanted requests to be sent at the start and end of the prediction, you would provide:  &#x60;&#x60;&#x60;json {   \&quot;version\&quot;: \&quot;5c7d5dc6dd8bf75c1acaa8565735e7986bc5b66206b55cca93cb72c9bf15ccaa\&quot;,   \&quot;input\&quot;: {     \&quot;text\&quot;: \&quot;Alice\&quot;   },   \&quot;webhook\&quot;: \&quot;https://example.com/my-webhook\&quot;,   \&quot;webhook_events_filter\&quot;: [\&quot;start\&quot;, \&quot;completed\&quot;] } &#x60;&#x60;&#x60;  Requests for event types &#x60;output&#x60; and &#x60;logs&#x60; will be sent at most once every 500ms. If you request &#x60;start&#x60; and &#x60;completed&#x60; webhooks, then they&#39;ll always be sent regardless of throttling. 
        /// </summary>
        /// <value>By default, we will send requests to your webhook URL whenever there are new outputs or the prediction has finished. You can change which events trigger webhook requests by specifying &#x60;webhook_events_filter&#x60; in the prediction request:  - &#x60;start&#x60;: immediately on prediction start - &#x60;output&#x60;: each time a prediction generates an output (note that predictions can generate multiple outputs) - &#x60;logs&#x60;: each time log output is generated by a prediction - &#x60;completed&#x60;: when the prediction reaches a terminal state (succeeded/canceled/failed)  For example, if you only wanted requests to be sent at the start and end of the prediction, you would provide:  &#x60;&#x60;&#x60;json {   \&quot;version\&quot;: \&quot;5c7d5dc6dd8bf75c1acaa8565735e7986bc5b66206b55cca93cb72c9bf15ccaa\&quot;,   \&quot;input\&quot;: {     \&quot;text\&quot;: \&quot;Alice\&quot;   },   \&quot;webhook\&quot;: \&quot;https://example.com/my-webhook\&quot;,   \&quot;webhook_events_filter\&quot;: [\&quot;start\&quot;, \&quot;completed\&quot;] } &#x60;&#x60;&#x60;  Requests for event types &#x60;output&#x60; and &#x60;logs&#x60; will be sent at most once every 500ms. If you request &#x60;start&#x60; and &#x60;completed&#x60; webhooks, then they&#39;ll always be sent regardless of throttling. </value>
        [DataMember(Name = "webhook_events_filter", EmitDefaultValue = false)]
        public List<PredictionsCreateRequest.WebhookEventsFilterEnum> WebhookEventsFilter { get; set; }

        /// <summary>
        /// Returns the string presentation of the object
        /// </summary>
        /// <returns>String presentation of the object</returns>
        public override string ToString()
        {
            StringBuilder sb = new StringBuilder();
            sb.Append("class PredictionsCreateRequest {\n");
            sb.Append("  Input: ").Append(Input).Append("\n");
            sb.Append("  Stream: ").Append(Stream).Append("\n");
            sb.Append("  VarVersion: ").Append(VarVersion).Append("\n");
            sb.Append("  Webhook: ").Append(Webhook).Append("\n");
            sb.Append("  WebhookEventsFilter: ").Append(WebhookEventsFilter).Append("\n");
            sb.Append("}\n");
            return sb.ToString();
        }

        /// <summary>
        /// Returns the JSON string presentation of the object
        /// </summary>
        /// <returns>JSON string presentation of the object</returns>
        public virtual string ToJson()
        {
            return Newtonsoft.Json.JsonConvert.SerializeObject(this, Newtonsoft.Json.Formatting.Indented);
        }

        /// <summary>
        /// To validate all properties of the instance
        /// </summary>
        /// <param name="validationContext">Validation context</param>
        /// <returns>Validation Result</returns>
        IEnumerable<System.ComponentModel.DataAnnotations.ValidationResult> IValidatableObject.Validate(ValidationContext validationContext)
        {
            yield break;
        }
    }

}
